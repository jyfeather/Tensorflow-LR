{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用DQN\n",
    "\n",
    "使用神经网络预测来替代查询Q table记录所有state action的奖励值。有两种思路：\n",
    "1. 输入state和action，通过神经网络，计算对应的Q值\n",
    "2. 输入state，通过神经网络，计算各个action的值。\n",
    "\n",
    "DQN有两个重要的技术：\n",
    "1. <span class=\"mark\">Experience replay</span>：能够抽取之前的经历进行学习\n",
    "2. <span class=\"mark\">Fixed Q-targets</span>：用于打乱经历之间的相关性，预测 Q 估计 的神经网络具备最新的参数, 而预测 Q 现实 的神经网络使用的参数则是很久以前的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN with experience replay\n",
    "初始化大小为 $N$ 的记忆库 $D$  \n",
    "使用随机权重 $\\theta$ 初始化行为-价值神经网络 $Q$  \n",
    "使用权重 $\\theta^{-}=\\theta$ 初始化目标的行为-价值函数 $\\hat{Q}$  \n",
    "循环从episode=1到$M$ \n",
    "> 初始化序列 $s_1=\\{x_1\\}$，以及预处理过的序列 $\\phi_1=\\phi(s_1)$  \n",
    "> 从t=1到$T$循环  \n",
    ">> 根据概率 $\\epsilon$，随机选择行为 $a_t$，或者选择 $a_t=\\arg\\max_a Q(\\phi(s_t),a;\\theta)$  \n",
    ">> 在模拟器中执行行为 $a_t$，并且观察奖励 $r_t$ 以及图像 $x_{t+1}$  \n",
    ">> 设置 $s_{t+1}=s_t,a_t,x_{t+1}$，并且预处理 $\\phi_{t+1}=\\phi(s_{t+1})$  \n",
    ">> 将序列 $(\\phi_t,a_t,r_t,\\phi_{t+1})$存入$D$  \n",
    ">> 从记忆库$D$中选择minibatch个序列 $(\\phi_j,a_j,r_j,\\phi_{j+1})$  \n",
    ">> 设置 $y_j$:  \n",
    ">>> 如果 episode 在 j+1 步终止，$y_j=r_j$  \n",
    ">>> 否则，$y_j = r_j+\\gamma\\max_{a'}\\hat{Q}(\\phi_{j+1},a';\\theta^{-})$\n",
    "\n",
    ">> 在 $(y_j - Q(\\phi_j,a_j;\\theta))^2$ 上执行梯度下降法，更新网络参数 $\\theta$  \n",
    ">> 每隔C步，更新 $\\hat{Q}=Q$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
