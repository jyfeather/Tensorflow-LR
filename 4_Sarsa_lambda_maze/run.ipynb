{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Sarsa(Lambda)实现迷宫游戏\n",
    "Sarsa 是一种单步更新法, 在环境中每走一步, 更新一次自己的行为准则, 我们可以在这样的 Sarsa 后面打一个括号, 说他是 Sarsa(0), 因为他等走完这一步以后直接更新行为准则. 如果延续这种想法, 走完这步, 再走一步, 然后再更新, 我们可以叫他 Sarsa(1). 同理, 如果等待回合完毕我们一次性再更新呢, 比如这回合我们走了 n 步, 那我们就叫 Sarsa(n). 为了统一这样的流程, 我们就有了一个 lambda 值来代替我们想要选择的步数, 这也就是 Sarsa(lambda) 的由来。\n",
    "\n",
    "Lambda取值在0到1之间，当 lambda 取0, 就变成了 Sarsa 的单步更新, 当 lambda 取 1, 就变成了回合更新, 对所有步更新的力度都是一样. 当 lambda 在 0 和 1 之间, 取值越大, 离宝藏越近的步更新力度越大. 这样我们就不用受限于单步更新的每次只能更新最近的一步, 我们可以更有效率的更新所有相关步了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game over\n"
     ]
    }
   ],
   "source": [
    "from maze_env import Maze\n",
    "from RL_brain import SarsaLambdaTable\n",
    "\n",
    "\n",
    "def update():\n",
    "    for episode in range(100):\n",
    "        # initial observation\n",
    "        observation = env.reset()\n",
    "\n",
    "        # RL choose action based on observation\n",
    "        action = RL.choose_action(str(observation))\n",
    "\n",
    "        # initial all zero eligibility trace\n",
    "        RL.eligibility_trace *= 0\n",
    "\n",
    "        while True:\n",
    "            # fresh env\n",
    "            env.render()\n",
    "\n",
    "            # RL take action and get next observation and reward\n",
    "            observation_, reward, done = env.step(action)\n",
    "\n",
    "            # RL choose action based on next observation\n",
    "            action_ = RL.choose_action(str(observation_))\n",
    "\n",
    "            # RL learn from this transition (s, a, r, s, a) ==> Sarsa\n",
    "            RL.learn(str(observation), action, reward, str(observation_), action_)\n",
    "\n",
    "            # swap observation and action\n",
    "            observation = observation_\n",
    "            action = action_\n",
    "\n",
    "            # break while loop when end of this episode\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "    # end of game\n",
    "    print('game over')\n",
    "    env.destroy()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = Maze()\n",
    "    RL = SarsaLambdaTable(actions=list(range(env.n_actions)))\n",
    "\n",
    "    env.after(100, update)\n",
    "    env.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化 $Q(s,a)$，对于所有 $s\\in\\mathcal{S}$，$a\\in\\mathcal{A}(s)$  \n",
    "循环（对于每个episode）\n",
    ">初始化 Eligibility trace。 $E(s,a)=0$，对于所有 $s\\in\\mathcal{S}$，$a\\in\\mathcal{A}(s)$  \n",
    ">初始化$S,A$  \n",
    ">循环（对于episode中的每一步）\n",
    ">>采取动作$A$，观察$R,S'$  \n",
    ">>根据$S'$，以及查询$Q$，选择$A'$  \n",
    ">>$\\delta \\leftarrow R + \\gamma Q(S',A') - Q(S,A)$  \n",
    ">>$E(S,A)\\leftarrow E(S,A)+1$  \n",
    ">> 对于所有 $s\\in\\mathcal{S}$，$a\\in\\mathcal{A}(s)$  \n",
    ">>>$Q(s,a)\\leftarrow Q(s,a)+\\alpha\\delta E(s,a)$  \n",
    ">>>$E(s,a)\\leftarrow \\gamma \\lambda E(s,a)$  \n",
    "\n",
    ">>$S \\leftarrow S',A\\leftarrow A'$  \n",
    "\n",
    ">直到S为终点"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
